{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidents_url = 'https://drive.google.com/uc?export=download&id=1U56rjU1el9mxuHp94a8tqUVuqMU4N1uk'\n",
    "presidents = pd.read_csv(presidents_url)\n",
    "presidents = presidents.iloc[:, [0, 4, 7]]\n",
    "presidents = presidents.groupby('President').sum().reset_index()\n",
    "presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "presidents.loc[:, 'Proportion Granted'] = presidents.iloc[:, 2]/presidents.iloc[:, 1]\n",
    "presidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total proportion of petitions granted\n",
    "\n",
    "percent_granted = presidents.iloc[:, 2].sum()/presidents.iloc[:, 1].sum()\n",
    "percent_granted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Proportion Granted', y='President', data=presidents, color='lightblue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Hypothesis:  Nixon was more likely to grant pardons (i.e. he had a different standard than the others).\n",
    "\n",
    "The alternative is that Nixon did not have a different standard, he just happened to President while receiving a higher proportion of the approvable petitions. Our point of view is that we could think of the set of all petitions as being made up of those that would be accepted or not by our perfect president resulting in 19.9% accepted; and then the petitions that a president receives are randomly selected from that sample, and maybe Nixon just ended up with a higher proportion of acceptable petitions by chance.\n",
    "\n",
    "Note for example that if a president receives only a small number of petitions the odds of them having half of them be acceptable would be high.\n",
    "\n",
    "---\n",
    "\n",
    "In a traditional Statistics class you would explore this question by building up some formulas that you could then use to make a decision Yes/No that Nixon was more likely to grant pardons than the other presidents.  However with computing technology where it is today, there is now a better way. And provided that we run the experiment often enough it will give the same result as the traditional method.\n",
    "\n",
    "The idea is to actually run the experiment. What we will do is draw the set of petitions for Nixon over and over from a population that has 19.9% of them being acceptable to our \"idealized president\" and see how often the proportion gets close to the 50% acceptable that Nixon ended up with. What we will then have is an estimate of how likely it was that Nixon found himself in this position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to need Python's pseudo random number generators to randomize our samples\n",
    "# Note that these are not truly random numbers. They start with a seed, and then algorithmically choose the results\n",
    "# This means, if you use the same seed, you get the same sequence.\n",
    "\n",
    "# These numbers though, as we change the seed, will behave like random numbers and share many of their properties.\n",
    "\n",
    "import random\n",
    "\n",
    "# the default is for random to use the system clock on your computer to get the seed, this because it uses seconds,\n",
    "# is unpredictiable enough for most applications\n",
    "\n",
    "# When testing your code, it can be useful to set the seed so the same sequence always happens\n",
    "# random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(presidents.loc[6, 'Petitions Received (Pardons)'])  # set the size of the sample to pull\n",
    "# Note I needed to convert this to int()\n",
    "\n",
    "total_petitions = int(presidents.loc[:, 'Petitions Received (Pardons)'].sum()) # Note I needed to convert these to int\n",
    "total_granted = int(presidents.loc[:, 'Pardons'].sum()) # Note I needed to convert these to int\n",
    "total_denied = total_petitions - total_granted # The other two are int, so this will be too.\n",
    "\n",
    "population = ['granted']*total_granted + ['denied']*total_denied\n",
    "# Note what we do here. We rebuild the entire population!  We can do this because with our computers, the \n",
    "# size of this thing does not matter until we get into the millions. There are other things to do, but \n",
    "# this idea of building the whole population and simmulating from it is the most generic.\n",
    "\n",
    "# Also note how easy it is to build our population in Python. \n",
    "# ['granted'] * total_granted make a list of length total_granted where each entry is 'granted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what the command random.sample is doing\n",
    "\n",
    "random.sample(population, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make this a function so we don't have to retype it all the time\n",
    "\n",
    "def experiment(N, s = size):\n",
    "    # N is the number of times to run the experiment\n",
    "    # s is a variable that will let us change the size of the sample to pull, the default value size is the number\n",
    "    # of petitions that Nixon received\n",
    "\n",
    "    result = pd.DataFrame([], columns = ['Pardons', 'Proportion Granted']) # Make a dataframe to catalogue the results\n",
    "    # Note I drop the size, because every sample will have the same size.\n",
    "    \n",
    "    for k in range(N):\n",
    "        \n",
    "        # random.choices(population, size)  \n",
    "        # use this command if we are sampling from the population with replacement\n",
    "    \n",
    "        sample = random.sample(population, s)\n",
    "        # use this command if we are sampling from the population without replacement\n",
    "    \n",
    "        row = pd.DataFrame([sample.count('granted'), sample.count('granted')/s], \n",
    "                       index = ['Pardons', 'Proportion Granted']).transpose()\n",
    "    \n",
    "        result = result.append(row)\n",
    "    \n",
    "    return result.reset_index().iloc[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1000 = experiment(1000)\n",
    "result1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So did any of these 1000 experimental Nixon's samples ever get close to real Nixon's 50%?\n",
    "\n",
    "sns.displot(result1000, x='Proportion Granted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Proportion Granted', data=result1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in 1000 attempts we got nowhere near Nixon's rate. This implies that indeed Nixon was a unique president in the use of the pardon power.\n",
    "\n",
    "Let's note that if the sample size is smaller (i.e. if the number of requests is low, the question changes).\n",
    "\n",
    "Run this a few times and note that the figure does not change much. \n",
    "\n",
    "Our estimate is that the probability that any president would approve 50% of their pardon requests is less than 1 in 1000 or less than 0.1 precent. We may want to run the experiment for 10000 times to see if we can get a finer result. Note that this does take time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result10000 = experiment(10000)\n",
    "sns.displot(result1000, x='Proportion Granted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again see that it is very unlikely.\n",
    "\n",
    "Just to illustrate how the sample sizes affects the spread of the results, consider a sample size of 10.  We expect to have some of these with a 5 in 10 or larger number of 'granted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1000 = experiment(1000, s=10)\n",
    "sns.displot(result1000, x='Proportion Granted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Proportion Granted', data=result1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(result1000.loc[:, 'Proportion Granted'] >= 0.5).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if the samples are of size 10, then 37 times our of 1000 we find more than 50% of the pardons approved by all presidents. So that puts the probability at 3.7 %.\n",
    "\n",
    "Note the precise number will vary every time we run this, though if we do the experiment more it will become more stable.\n",
    "\n",
    "Also note that the Bell Shape we saw in the previous exampls is breaking down here. This is because the propotion stops at 0.0, and so the result sort of stack up there. This is an example of where the resampling experiment is providing better information than a more traditional statistics approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do another example\n",
    "\n",
    "This dataset is from the PPP loans given out as part of the CARES Act in 2020. It is a database on the loans awarded for more than $150,000 witha. bit of information about who they were awarded to.\n",
    "\n",
    "I pulled this dataset from a project on kaggle.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a big data set and it did not play well with Google Drive.\n",
    "PPP = pd.read_csv('PPP_data_150k_plus.csv').iloc[:, [0, 4, -4]] # only three columns for what we want to do today\n",
    "PPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(PPP.loc[:, 'LoanRange'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this is a nice example as it the first one we are doing where the size of the file is too big to open in Excel or similar on many computers. It is a dataset that really needs to be dealt with by a tool like Python or R.\n",
    "\n",
    "What type of variable are we getting for 'LoanRange'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the ones we have no State assigned to.\n",
    "# In reality it would probably be worth figuring out why some of them do not have a state assigned.\n",
    "\n",
    "no_state_index = PPP.loc[:, 'State'] == 'XX'\n",
    "no_state = PPP.loc[no_state_index, :]\n",
    "state = PPP.drop(no_state.index, axis=0)\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many jobs were retained by the loans by value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_by_value = state.groupby(['State', 'LoanRange']).mean()\n",
    "state_by_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note this is a multi-index. It is possible to peal off the first one \n",
    "# specifying a state we want to look more closely at\n",
    "\n",
    "state_by_value.loc['CO', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did Colorado do compared to the whole country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_by_value = state.groupby('LoanRange').mean()\n",
    "whole_by_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_loans = state.loc[ state.loc[:, 'LoanRange']=='a $5-10 million']\n",
    "# We will drop the ones that are missing 'JobsRetained' values. It would be nice with more time to understand\n",
    "# why these are missing for some.\n",
    "large_loans = large_loans.loc[ pd.notna(large_loans.loc[:, 'JobsRetained'])]\n",
    "sns.histplot(large_loans.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again worth pausing here and pointing out:  Note a nice bell curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can visualize the distribution with a boxplot also\n",
    "sns.boxplot(x = 'JobsRetained', data = large_loans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do our sampling expriment to see if Colorado was unique or not. In this case the dataset we will sample from is already built for us, it is the state dataframe with the jobs saved for each PPP loan in the large category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to know how large the sample was (and also check for missing values)\n",
    "large_loans.groupby('State').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make this a function so we don't have to retype it all the time\n",
    "\n",
    "def experiment(N, s = size, population = list(large_loans.loc[:, 'JobsRetained'])):\n",
    "    # N is the number of times to run the experiment\n",
    "    # s is a variable that will let us change the size of the sample to pull, the default value size is the number\n",
    "    # of large loans in Colorado\n",
    "\n",
    "    result = pd.DataFrame([], columns = ['Mean Jobs Retained']) # Make a dataframe to catalogue the results\n",
    "    \n",
    "    for k in range(N):\n",
    "        \n",
    "        # random.choices(population, size).mean()  \n",
    "        # use this command if we are sampling from the population with replacement\n",
    "    \n",
    "        sample = np.mean(random.sample(population, s))\n",
    "        # use this command if we are sampling from the population without replacement\n",
    "    \n",
    "        row = pd.DataFrame([sample], \n",
    "                       index = ['Mean Jobs Retained']).transpose()\n",
    "    \n",
    "        result = result.append(row)\n",
    "    \n",
    "    return result.reset_index().iloc[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = experiment(100)\n",
    "sns.boxplot(x = 'Mean Jobs Retained', data = result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x='Mean Jobs Retained', data=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[ result.loc[:, 'Mean Jobs Retained']>376.455556].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
